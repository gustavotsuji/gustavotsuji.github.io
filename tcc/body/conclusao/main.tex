% ---
% Conclusão
% ---
\chapter{Conclusão}
% ---
A regressão logística possui um comportamento mais estável, podendo ser facilmente usado em problemas que propicie uma separação linear dos dados. Eventualmente pode-se feature não lineares para que elas tenham um comportamento linear. Além disso, um dos problemas que pode ocorrer na regressão logística é o overfitting (existe tradução?) mas que pode ser contornado adicionando parâmetros l2 ou l1. Em situações em que é preciso lidar com um volume grande de dados (como ocorre com Big Data), a regressão logística permite o uso escalável utilizando recursos como ADMM. 

O Random forest possui vantagens como a possibilidade de trabalhar com base de dados que não tenham um comportamento linear. Além disso, elas podem tratar variáveis categóricas, fato que é complicado quando se trabalha com regressão logística (até possui um tratamento para tal (transformar a variável categórica em variáveis dummies) mas que pode tornar o cálculo mais complexo), já que o random forest são árvores de decisões. Com o uso de bagging ou boosting, é possível trabalhar com uma grande quantidade de variáveis, além de realizar diversos treinos. Além disso, a random forest pode selecionar quais são as variáveis mais relevantes independente da quantidade de váriaveis que ela receba inicialmente.




%\lipsum[31-33]
